---
title: "Twitter Conversation Data"
author: "Disha Srivastava"
date: "5/1/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

Twitter Conversation Data

### Load libraries 
```{r}
# load twitter library 
library(rtweet)

# plotting and pipes - tidyverse!
library(ggplot2)
library(dplyr)

# text mining library
library(tidytext)
```

### Setting up the API 
```{r}
# Note we have removed the api keys and tokens as this code is published in GitHub. Hence, the wordcloud may not be working at the moment. 

# whatever name you assigned to your created app
appname <- "x"

## api key (example below is not a real key)
key <- "x"

## api secret (example below is not a real key)
secret <- "x"

# create token named "twitter_token"
twitter_token <- create_token(
  app = appname,
  consumer_key = key,
  consumer_secret = secret,
  access_token = 'x',
  access_secret = 'x')
```

### Gather up Tweets 
```{r}
data <- search_tweets("#economy", n = 600,
                             include_rts = FALSE)
```

### Display Tweets 
```{r}
head(data$text)
```

## Cleaning the data 
```{r}
# Load libraries 
library(wordcloud)
library(RColorBrewer)
library(wordcloud2)
library(tm)

#Create a vector containing only the text
text <- data$text

# Create a corpus  
docs <- Corpus(VectorSource(text))

docs <- docs %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
```

# Organizing the text data 
```{r}
dtm <- TermDocumentMatrix(docs) 
matrix <- as.matrix(dtm) 
words <- sort(rowSums(matrix),decreasing=TRUE) 
df <- data.frame(word = names(words),freq=words)
```


### Generating the word cloud 
```{r}
# Generate the word cloud
set.seed(1234) # for reproducibility 
wordcloud(words = df$word, freq = df$freq, min.freq = 1,           max.words=200, random.order=FALSE, rot.per=0.35,            colors=brewer.pal(8, "Dark2"))
```
